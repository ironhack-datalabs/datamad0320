# OBJETIVO 

1) Hacer Web Scraping de Medium para los años 2020/2019 y conseguir un volumen de artículos considerable.

2) Entrenar un modelo de supervised-learning para predecir el número de claps que puede llegar a tener una publicación (sin tener en cuenta las variables textuales)

- X: Tiempo publicación, Día publicación, Minutos de Lectura, Publisher. 

3) (SI ME DIERA TIEMPO) Predecir el número de claps entrenado un modelo que tenga en cuenta las variables textuales (Utilizando Natural Language Processing)

- X: Tiempo publicación, Día publicación, Minutos de Lectura, Publisher + [CUERPO ARTÍCULO] + [TÍTULO ARTÍCULO]

4) Obtener estadísticas relevantes 

- Influye la hora a la que se publica el post para tener mayor número de claps?
- Influye la época del año?
- Influye el reading time del post? 
- Influye el Publisher bajo el cual publicas el post (Towards Data Science, Good Programming, Heart Beat...)
- Qué palabras incluiría un post para tener mayor número de claps?

# IDEA

Para obtener el dataset me gustaría seguir un esquema parecido a este. Bien ampliar este dataset con artículos más actuales o crearme el mío propio.

- https://www.kaggle.com/hsankesara/medium-articles

# A TENER EN CUENTA:

He estado ya probado cómo scrappear Medium (tengo ya un modelo de scrapeo)